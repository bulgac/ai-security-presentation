Презентация: OWASP Топ 10 уязвимостей для LLM-приложений в 2025
--------------------------------------------------------------------------------
Слайд 1: Введение

  Проект OWASP (Open Worldwide Application Security Project) - это некоммерческая организация, занимающаяся улучшением безопасности программного обеспечения.
В частности, проект "OWASP Top 10 для приложений LLM" (Large Language Model Applications) — это инициатива, начатая в 2023 году, движимая сообществом, с целью выявления и устранения проблем безопасности, специфичных для приложений искусственного интеллекта.
Он представляет собой список 10 наиболее распространенных уязвимостей, с которыми сталкиваются большие языковые модели сегодня.
Цель проекта — повысить осведомленность и заложить основу для безопасного использования LLM.
Этот список является результатом идей и опыта сообщества разработчиков, специалистов по данным и экспертов по безопасности со всего мира, которые стремятся создавать более безопасные ИИ-приложения.
Все материалы проекта создаются сообществом и распространяются под открытыми лицензиями, такими как Creative Commons

Cписок 10 наиболее распространенных уязвимостей
 LLM01: Инъекция Промпта (Prompt Injection)
 LLM02: Раскрытие Конфиденциальной Информации (Sensitive Information Disclosure)
 LLM03: Риски Цепочки Поставок (Supply Chain)
 LLM04: Отравление Данных и Моделей (Data and Model Poisoning)
 LLM05: Некорректная Обработка Вывода (Improper Output Handling)
 LLM06: Избыточная Агентность (Excessive Agency)
 LLM07: Утечка Системного Промпта (System Prompt Leakage)
 LLM08: Слабости Векторов и Встраиваний (Vector and Embedding Weaknesses)
 LLM09: Дезинформация (Misinformation)
 LLM10: Неограниченное Потребление (Unbounded Consumption)

--------------------------------------------------------------------------------
Слайд 2: LLM01: Инъекция Промпта (Prompt Injection)

Эта уязвимость возникает, когда пользовательские промпты изменяют поведение или вывод LLM непреднамеренным образом.
Злоумышленники могут манипулировать промптами для изменения поведения модели или обхода протоколов безопасности LLM.
Это может быть прямая (намеренное изменение поведения модели) или непрямая (через внешние источники, такие как веб-сайты или файлы) инъекция.

--------------------------------------------------------------------------------
Слайд 3: LLM02: Раскрытие Конфиденциальной Информации (Sensitive Information Disclosure)

LLM случайно раскрывают конфиденциальные данные, такие как личные записи пользователей (PII), финансовые детали, медицинские записи, коммерческие тайны, учетные данные безопасности или данные для обучения.
Это может привести к несанкционированному доступу к данным, нарушениям конфиденциальности и утечкам интеллектуальной собственности.

--------------------------------------------------------------------------------
Слайд 4: LLM03: Риски Цепочки Поставок (Supply Chain Risks)

Цепочки поставок LLM уязвимы к различным угрозам, которые могут повлиять на целостность обучающих данных, моделей и платформ развертывания.
Атакующие могут использовать уязвимости в сторонних компонентах (например, библиотеках Python, устаревших компонентах или предварительно обученных моделях), чтобы внедрить вредоносный код или инструкции, что может привести к предвзятым результатам, нарушениям безопасности или сбоям системы.

--------------------------------------------------------------------------------
Слайд 5: LLM04: Отравление Данных и Моделей (Data and Model Poisoning)

Отравление данных происходит, когда данные на этапах предварительного обучения, тонкой настройки или встраивания манипулируются для внедрения уязвимостей, бэкдоров или искажений.
Это может поставить под угрозу безопасность, производительность или этичное поведение модели, приводя к вредоносным или искаженным результатам.
Вредоносный код может быть внедрен напрямую в процесс обучения или пользователи могут неосознанно внедрять чувствительную информацию.

--------------------------------------------------------------------------------
Слайд 6: LLM05: Некорректная Обработка Вывода (Improper Output Handling)

Эта уязвимость относится к недостаточной проверке, санитарной обработке и обработке выходных данных, генерируемых LLM, прежде чем они передаются в другие компоненты или системы.
Успешная эксплуатация может привести к атакам XSS, CSRF в веб-браузерах, а также SSRF, выполнению удаленного кода (RCE) или повышению привилегий в серверных системах.

--------------------------------------------------------------------------------
Слайд 7: LLM06: Избыточная Агентность (Excessive Agency)

LLM-системам часто предоставляется степень автономности (агентности) для вызова функций или взаимодействия с другими системами через расширения (плагины).
Избыточная агентность — это уязвимость, позволяющая выполнять вредоносные действия в ответ на неожиданные, неоднозначные или манипулируемые выходные данные LLM, вызванные галлюцинациями или вредоносными инъекциями промптов.

--------------------------------------------------------------------------------
Слайд 8: LLM07: Утечка Системного Промпта (System Prompt Leakage)

Уязвимость утечки системного промпта относится к риску того, что системные промпты или инструкции, используемые для управления поведением LLM, могут содержать конфиденциальную информацию, которую не предполагалось раскрывать.
Обнаружение этой информации может быть использовано злоумышленниками для облегчения других атак, например, для кражи учетных данных, раскрытия внутренних правил или фильтрующих критериев.

--------------------------------------------------------------------------------
Слайд 9: LLM08: Слабости Векторов и Встраиваний (Vector and Embedding Weaknesses)

Описание: Векторные и встраиваемые уязвимости представляют значительные риски безопасности в системах, использующих Retrieval Augmented Generation (RAG) с LLM.
Слабости в том, как векторы и встраивания генерируются, хранятся или извлекаются, могут быть использованы для внедрения вредоносного контента, манипулирования выводами модели или доступа к конфиденциальной информации.

--------------------------------------------------------------------------------
Слайд 10: LLM09: Дезинформация (Misinformation)

Дезинформация от LLM — это основная уязвимость для приложений, полагающихся на эти модели.
Дезинформация возникает, когда LLM генерируют ложную или вводящую в заблуждение информацию, которая кажется правдоподобной (так называемые "галлюцинации").
Это может привести к нарушениям безопасности, репутационному ущербу и юридической ответственности.

--------------------------------------------------------------------------------
Слайд 11: LLM10: Неограниченное Потребление (Unbounded Consumption)

Эта уязвимость относится к ситуациям, когда приложение LLM позволяет пользователям выполнять чрезмерные и неконтролируемые выводы, что приводит к рискам, таким как отказ в обслуживании (DoS), экономические потери (Denial of Wallet), кража модели и деградация сервиса. Высокие вычислительные требования LLM делают их уязвимыми для эксплуатации ресурсов и несанкционированного использования

--------------------------------------------------------------------------------
Слайд 12: Основные выводы и рекомендации по безопасности LLM-приложений

Комплексный подход к безопасности:
    Большие языковые модели, какими бы сложными они ни были, остаются инструментами, подверженными ошибкам и непредсказуемым результатам.
    К ним следует относиться как к "новичку в команде", всегда тщательно проверяя их работу, чтобы избежать ошибок.

Строгая валидация и очистка данных:
    Все данные, поступающие в LLM и выходящие из нее, должны быть тщательно проверены и очищены, прежде чем они смогут взаимодействовать с внутренними системами или, тем более, с внешним пользователем.
        Включает в себя проверку входных данных на соответствие разумным ограничениям по размеру и очистку выходных данных для предотвращения нежелательного выполнения кода.

Принцип наименьших привилегий и разделение функций:
    Минимизируйте функциональность и разрешения, предоставляемые LLM и связанным с ней расширениям (плагинам).
    Критические меры контроля, такие как разделение привилегий и проверка границ авторизации, не должны делегироваться LLM, а должны выполняться независимыми системами.

Контроль и участие человека:
    Внедряйте механизмы "человек в контуре" (human-in-the-loop) для операций с высоким риском, требуя одобрения действий со стороны человека.
    Поощряйте пользователей к перепроверке выходных данных LLM с использованием проверенных внешних источников.

Надёжность цепочки поставок:
    Регулярно проводите аудит цепочки поставок программного обеспечения, используйте подписанные и проверенные зависимости, а также внедряйте безопасные методы разработки.
        Поддерживайте актуальный Software Bill of Materials (SBOM) для отслеживания всех зависимостей в вашей среде.


Управление ресурсами и предотвращение DoS:
    Устанавливайте разумные ограничения скорости и квоты пользователей, контролируйте распределение ресурсов, а также внедряйте тайм-ауты и механизмы регулирования для ресурсоемких операций.
        Проект "Неограниченное потребление" (Unbounded Consumption) расширяет концепцию "отказа в обслуживании", включая риски, связанные с управлением ресурсами и непредвиденными расходами.

Постоянное тестирование и мониторинг:
    Регулярно проводите адверсариальное тестирование (red teaming) и симуляции атак, рассматривая модель как недоверенного пользователя.
        Внедряйте комплексное логирование, мониторинг и обнаружение аномалий для выявления необычных паттернов потребления ресурсов и вывода LLM


--------------------------------------------------------------------------------
Слайд 13: Ссылки на источники

https://genai.owasp.org/llm-top-10/
https://www.legitsecurity.com/aspm-knowledge-base/llm-security-risks
https://portswigger.net/web-security/llm-attacks
https://arxiv.org/abs/2306.05499
https://github.com/LLMSecurity/HouYi


